{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87a4fc269cc4991",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# ğŸš¦ Traffic Prediction & Optimization\n",
    "\n",
    "## Ziel\n",
    "Dieses Notebook zeigt eine **vollstÃ¤ndige Analyse- und Modellierungs-Pipeline** zur **Vorhersage von Verkehrsaufkommen** â€“ von der Datenbasis bis zum Modellvergleich.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ Analyse-Pipeline\n",
    "\n",
    "- ğŸ“Š **Datenbasis**\n",
    "  - Synthetische Verkehrsdaten generieren **oder**\n",
    "  - CSV-Datei laden (mit `ds` und `y`)\n",
    "- ğŸ” **Explorative Datenanalyse (EDA)**\n",
    "  - Zeitliche Muster\n",
    "  - Verteilungen\n",
    "  - SaisonalitÃ¤ten\n",
    "- ğŸ› ï¸ **Feature Engineering**\n",
    "  - Lag-Features\n",
    "  - Rolling Statistics\n",
    "  - Kalender-Features (Wochentag, Feiertage etc.)\n",
    "  - Wetter-Features (optional)\n",
    "- ğŸ¤– **Modelle**\n",
    "  - Lineare Regression\n",
    "  - Random Forest\n",
    "  - *(Optional)* Prophet\n",
    "  - *(Optional)* LSTM\n",
    "- ğŸ“ˆ **Evaluation & Vergleich**\n",
    "  - Modellvergleich anhand geeigneter Metriken\n",
    "  - Visualisierung der Prognosen\n",
    "- ğŸ§ª **Optional**\n",
    "  - MLflow Tracking fÃ¼r Experimente\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Problemdefinition\n",
    "\n",
    "- **Zielvariable:**\n",
    "  `y` â€“ Verkehrsaufkommen\n",
    "\n",
    "- **Zeitspalte:**\n",
    "  `ds` â€“ Datetime (z. B. stÃ¼ndlich oder tÃ¤glich)\n",
    "\n",
    "- **Laufzeit:**\n",
    "  â±ï¸ *< 5 Minuten auf CPU*\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“˜ So nutzt du dieses Notebook\n",
    "\n",
    "- âœ… Laufzeit < 5 Minuten auf CPU\n",
    "- ğŸ” Zufallsseeds sind gesetzt fÃ¼r Reproduzierbarkeit\n",
    "- ğŸ§± Du kannst:\n",
    "  - synthetische Verkehrsdaten erzeugen **oder**\n",
    "  - eine eigene CSV-Datei laden (`ds`, `y`)\n",
    "- ğŸ“Š FÃ¼hre EDA durch, trainiere mehrere Modelle und vergleiche sie\n",
    "- ğŸ§  Optional:\n",
    "  - MLflow fÃ¼r Experiment-Tracking\n",
    "  - Prophet oder LSTM fÃ¼r fortgeschrittene Zeitreihenmodelle\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ Imports & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81322b5fbfd0088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T16:08:07.720354600Z",
     "start_time": "2026-01-22T16:08:07.639849700Z"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# Imports & Globales Setup\n",
    "# =====================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =====================================\n",
    "# Machine Learning\n",
    "# =====================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# =====================================\n",
    "# Plot Styling\n",
    "# =====================================\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# =====================================\n",
    "# Reproduzierbarkeit\n",
    "# =====================================\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# =====================================\n",
    "# Optionale AbhÃ¤ngigkeiten\n",
    "# =====================================\n",
    "\n",
    "# --- MLflow ---\n",
    "USE_MLFLOW = True\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "except Exception as e:\n",
    "    USE_MLFLOW = False\n",
    "    print(\"MLflow nicht verfÃ¼gbar:\", e)\n",
    "\n",
    "# --- Prophet ---\n",
    "USE_PROPHET = True\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "except Exception as e:\n",
    "    USE_PROPHET = False\n",
    "    print(\"Prophet nicht verfÃ¼gbar:\", e)\n",
    "\n",
    "# --- TensorFlow / LSTM ---\n",
    "USE_TF = True\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "except Exception as e:\n",
    "    USE_TF = False\n",
    "    print(\"TensorFlow nicht verfÃ¼gbar:\", e)\n",
    "\n",
    "print(f\"MLflow: {USE_MLFLOW} | Prophet: {USE_PROPHET} | TensorFlow: {USE_TF}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520cc3ab4424c922",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Daten: Laden oder synthetisch generieren\n",
    "\n",
    "In diesem Abschnitt werden die **Verkehrsdaten** entweder aus einer eigenen CSV-Datei geladen\n",
    "oder **synthetisch erzeugt**, um die komplette Pipeline reproduzierbar zu demonstrieren.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¥ Eigene Daten laden\n",
    "- CSV-Datei mit:\n",
    "  - **`ds`** â†’ Datum/Zeit (Datetime)\n",
    "  - **`y`** â†’ Verkehrsaufkommen (Zielvariable)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§ª Synthetische Daten (optional)\n",
    "- Realistische Zeitmuster:\n",
    "  - Tages- und Wochenzyklen\n",
    "  - Rauschen / ZufallseinflÃ¼sse\n",
    "  - Trend-Komponente\n",
    "\n",
    "---\n",
    "\n",
    "### â• Optionale Zusatzfeatures\n",
    "- **Wetter** (z. B. Temperatur, Regen)\n",
    "- **Feiertag** (binÃ¤r oder kategorial)\n",
    "\n",
    "Diese Features kÃ¶nnen spÃ¤ter im **Feature Engineering** genutzt werden, um die PrognosequalitÃ¤t zu verbessern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d4ab63c09ab81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T16:08:07.803811600Z",
     "start_time": "2026-01-22T16:08:07.724355300Z"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 2. Daten: Laden oder synthetisch generieren\n",
    "# =====================================\n",
    "\n",
    "USE_CSV = False\n",
    "CSV_PATH = \"data/traffic.csv\"\n",
    "\n",
    "\n",
    "def generate_realistic_traffic_data(days=60, start=\"2024-01-01\"):\n",
    "    \"\"\"\n",
    "    Generiert realistische stÃ¼ndliche Verkehrsdaten\n",
    "    mit Tages-, Wochenmustern, Trend und Rauschen.\n",
    "    \"\"\"\n",
    "    # Zeitachse (stÃ¼ndlich)\n",
    "    dates = pd.date_range(start=start, periods=days * 24, freq=\"h\")\n",
    "    t = np.arange(len(dates))\n",
    "\n",
    "    # Muster & Effekte\n",
    "    daily_pattern = 30 * np.sin(2 * np.pi * t / 24)\n",
    "    weekly_pattern = 10 * np.sin(2 * np.pi * t / (24 * 7))\n",
    "    trend = np.linspace(0, 5, len(t))\n",
    "    noise = np.random.normal(0, 4, len(t))\n",
    "\n",
    "    # Traffic berechnen\n",
    "    traffic = 50 + daily_pattern + weekly_pattern + trend + noise\n",
    "    traffic = np.clip(traffic, 5, 100)\n",
    "\n",
    "    # Optionale Zusatzfeatures\n",
    "    weather = np.random.choice(\n",
    "        [\"Sonnig\", \"BewÃ¶lkt\", \"Regen\"],\n",
    "        size=len(t),\n",
    "        p=[0.5, 0.3, 0.2]\n",
    "    )\n",
    "\n",
    "    is_holiday = np.zeros(len(t))\n",
    "    is_holiday[::168] = 1  # ca. einmal pro Woche\n",
    "\n",
    "    # DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"ds\": dates,\n",
    "        \"y\": traffic,\n",
    "        \"Geschwindigkeit\": 120 - traffic * 0.5 + np.random.normal(0, 5, len(t)),\n",
    "        \"Wetter\": weather,\n",
    "        \"Feiertag\": is_holiday.astype(int),\n",
    "    })\n",
    "\n",
    "    # Zeitbasierte Features\n",
    "    df[\"Stunde\"] = df[\"ds\"].dt.hour\n",
    "    df[\"Wochentag\"] = df[\"ds\"].dt.dayofweek\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# Daten laden oder generieren\n",
    "# =====================================\n",
    "\n",
    "if USE_CSV:\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "else:\n",
    "    df = generate_realistic_traffic_data(days=60)\n",
    "\n",
    "print(f\"Datensatz: {df.shape}\")\n",
    "print(f\"Zeitraum: {df['ds'].min()} bis {df['ds'].max()}\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1480d5e48c80bd",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ EDA â€“ Explorative Datenanalyse\n",
    "\n",
    "Ziel der explorativen Datenanalyse ist es, **Strukturen, Muster und AuffÃ¤lligkeiten**\n",
    "in den Verkehrsdaten zu erkennen, bevor Features erzeugt oder Modelle trainiert werden.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” Fragestellungen\n",
    "- Wie entwickelt sich das Verkehrsaufkommen Ã¼ber die Zeit?\n",
    "- Gibt es **Tages- oder Wochenmuster**?\n",
    "- Wie ist die Verteilung der Zielvariable `y`?\n",
    "- Gibt es ZusammenhÃ¤nge mit Wetter oder Feiertagen?\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ˆ Analyseschritte\n",
    "- Zeitreihenplot des Verkehrsaufkommens\n",
    "- Tagesprofil (durchschnittlicher Traffic je Stunde)\n",
    "- Wochenprofil (durchschnittlicher Traffic je Wochentag)\n",
    "- Verteilungen & Boxplots\n",
    "- Korrelationen zwischen numerischen Features\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Erkenntnisse (Platzhalter)\n",
    "> Die wichtigsten Beobachtungen aus der EDA werden hier kurz zusammengefasst\n",
    "> (z. B. starke Rush-Hour-Effekte, geringerer Traffic an Wochenenden etc.).\n",
    "\n",
    "Diese Erkenntnisse flieÃŸen direkt in das **Feature Engineering** und die **Modellauswahl** ein.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a538dc527e50d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T16:08:07.838331600Z",
     "start_time": "2026-01-22T16:08:07.805813600Z"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 3. EDA â€“ Explorative Datenanalyse\n",
    "# =====================================\n",
    "\n",
    "print(\"Deskriptive Statistik der Zielvariable y:\")\n",
    "display(df[\"y\"].describe())\n",
    "\n",
    "# -------------------------------------\n",
    "# Visualisierungen\n",
    "# -------------------------------------\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# 1ï¸âƒ£ Traffic Ã¼ber Zeit\n",
    "axes[0, 0].plot(df[\"ds\"], df[\"y\"], linewidth=1)\n",
    "axes[0, 0].set_title(\"Traffic Ã¼ber Zeit\")\n",
    "axes[0, 0].set_ylabel(\"y\")\n",
    "\n",
    "# 2ï¸âƒ£ Durchschnittlicher Traffic pro Stunde\n",
    "hourly_mean = df.groupby(\"Stunde\")[\"y\"].mean()\n",
    "axes[0, 1].bar(hourly_mean.index, hourly_mean.values)\n",
    "axes[0, 1].set_title(\"Ã˜ Traffic pro Stunde\")\n",
    "axes[0, 1].set_xlabel(\"Stunde\")\n",
    "\n",
    "# 3ï¸âƒ£ Durchschnittlicher Traffic pro Wochentag\n",
    "dow_mean = df.groupby(\"Wochentag\")[\"y\"].mean()\n",
    "axes[1, 0].plot(dow_mean.index, dow_mean.values, marker=\"o\", linewidth=2)\n",
    "axes[1, 0].set_title(\"Ã˜ Traffic pro Wochentag\")\n",
    "axes[1, 0].set_xticks(range(7))\n",
    "axes[1, 0].set_xticklabels([\"Mo\", \"Di\", \"Mi\", \"Do\", \"Fr\", \"Sa\", \"So\"])\n",
    "\n",
    "# 4ï¸âƒ£ Verteilung der Zielvariable\n",
    "axes[1, 1].hist(df[\"y\"], bins=30, edgecolor=\"black\")\n",
    "axes[1, 1].set_title(\"Verteilung von y\")\n",
    "axes[1, 1].set_xlabel(\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bc9638f1b53e3",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Train/Test Split & Feature Engineering\n",
    "\n",
    "In diesem Abschnitt werden aus den Rohdaten **modellrelevante Features** erzeugt\n",
    "und die Zeitreihe **korrekt in Trainings- und Testdaten** aufgeteilt.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ Feature Engineering\n",
    "\n",
    "### Zeitbasierte Features\n",
    "- Stunde (`Stunde`)\n",
    "- Wochentag (`Wochentag`)\n",
    "- Optional: Monat, Wochenende, Feiertag\n",
    "\n",
    "### Lag-Features\n",
    "- VerzÃ¶gerte Zielwerte:\n",
    "  - `y_lag_1`\n",
    "  - `y_lag_24`\n",
    "  - `y_lag_168` (eine Woche)\n",
    "\n",
    "### Rolling Features\n",
    "- Gleitende Mittelwerte:\n",
    "  - `y_roll_24`\n",
    "  - `y_roll_168`\n",
    "\n",
    "Diese Features helfen den Modellen, **kurz- und mittelfristige Muster** zu lernen.\n",
    "\n",
    "---\n",
    "\n",
    "## â±ï¸ Zeitreihen-Train/Test-Split\n",
    "\n",
    "- Keine zufÃ¤llige Durchmischung âŒ\n",
    "- Split erfolgt **chronologisch**\n",
    "- Typischer Split:\n",
    "  - **Train:** erste 80 %\n",
    "  - **Test:** letzte 20 %\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Ziel\n",
    "\n",
    "- Vermeidung von **Data Leakage**\n",
    "- Realistische Simulation einer echten Vorhersagesituation\n",
    "- Einheitliche Feature-Basis fÃ¼r alle Modelle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212f38196d50752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T16:08:07.891191200Z",
     "start_time": "2026-01-22T16:08:07.841334200Z"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 4. Train / Test Split (Zeitreihe)\n",
    "# =====================================\n",
    "\n",
    "SPLIT_RATIO = 0.8\n",
    "split_idx = int(len(df) * SPLIT_RATIO)\n",
    "\n",
    "train_df = df.iloc[:split_idx].copy()\n",
    "test_df = df.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Train: {train_df.shape}\")\n",
    "print(f\"Test:  {test_df.shape}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# Feature Engineering\n",
    "# =====================================\n",
    "\n",
    "def create_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Erstellt Feature-Matrix mit:\n",
    "    - Kalenderfeatures\n",
    "    - Lag-Features\n",
    "    - Rolling Mean Features\n",
    "    - Wetter-Indikatoren (optional)\n",
    "    \"\"\"\n",
    "    X = pd.DataFrame(index=data.index)\n",
    "\n",
    "    # Kalenderfeatures\n",
    "    X[\"hour\"] = data[\"Stunde\"]\n",
    "    X[\"day_of_week\"] = data[\"Wochentag\"]\n",
    "    X[\"is_holiday\"] = data[\"Feiertag\"]\n",
    "\n",
    "    # Lag-Features\n",
    "    for lag in [1, 6, 24]:\n",
    "        X[f\"lag_{lag}\"] = data[\"y\"].shift(lag)\n",
    "\n",
    "    # Rolling Means\n",
    "    for window in [6, 24]:\n",
    "        X[f\"rolling_mean_{window}\"] = data[\"y\"].rolling(window).mean()\n",
    "\n",
    "    # Wetter (falls vorhanden)\n",
    "    if \"Wetter\" in data.columns:\n",
    "        X[\"is_rain\"] = (data[\"Wetter\"] == \"Regen\").astype(int)\n",
    "        X[\"is_cloudy\"] = (data[\"Wetter\"] == \"BewÃ¶lkt\").astype(int)\n",
    "    else:\n",
    "        X[\"is_rain\"] = 0\n",
    "        X[\"is_cloudy\"] = 0\n",
    "\n",
    "    # Fehlende Werte durch Backfilling behandeln\n",
    "    return X.bfill()\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# Feature- & Zieldefinition\n",
    "# =====================================\n",
    "\n",
    "X_train = create_features(train_df)\n",
    "X_test = create_features(test_df)\n",
    "\n",
    "y_train = train_df[\"y\"].values\n",
    "y_test = test_df[\"y\"].values\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "display(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a26545cbdf9c6",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Modelle: Linear Regression & Random Forest\n",
    "\n",
    "In diesem Abschnitt werden zwei klassische Regressionsmodelle\n",
    "fÃ¼r die Verkehrsprognose trainiert und verglichen:\n",
    "\n",
    "- **Lineare Regression** als einfache, gut interpretierbare Baseline\n",
    "- **Random Forest Regressor** zur Modellierung nichtlinearer ZusammenhÃ¤nge\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Modelle im Ãœberblick\n",
    "\n",
    "### 1ï¸âƒ£ Lineare Regression\n",
    "- Schnelles Baseline-Modell\n",
    "- Gut interpretierbar\n",
    "- Erwartung: begrenzte Leistung bei komplexen Mustern\n",
    "\n",
    "### 2ï¸âƒ£ Random Forest Regressor\n",
    "- Ensemble aus EntscheidungsbÃ¤umen\n",
    "- Kann NichtlinearitÃ¤ten und Interaktionen erfassen\n",
    "- Robuster gegenÃ¼ber AusreiÃŸern\n",
    "- HÃ¶herer Rechenaufwand (aber < 5 Min CPU)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§ª Trainingsstrategie\n",
    "\n",
    "- Training auf **Train-Daten**\n",
    "- Evaluation auf **Test-Daten**\n",
    "- Zeitreihen-konformer Split (kein Shuffle)\n",
    "- Metriken:\n",
    "  - MAE\n",
    "  - RMSE\n",
    "  - RÂ²\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Ziel\n",
    "\n",
    "- Quantitativer Vergleich einfacher vs. komplexerer Modelle\n",
    "- Grundlage fÃ¼r spÃ¤tere Erweiterungen (Prophet, LSTM)\n",
    "- Entscheidung, ob Feature Engineering ausreichend ist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9442d-5c74-4db2-b502-fdfb3b72afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 5. Modelle: Linear Regression & Random Forest\n",
    "# =====================================\n",
    "\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Berechnet gÃ¤ngige Regressionsmetriken.\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "# =====================================\n",
    "# Optional: MLflow Setup\n",
    "# =====================================\n",
    "\n",
    "if USE_MLFLOW:\n",
    "    mlflow.set_experiment(\"Traffic Prediction & Optimization\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 1ï¸âƒ£ Linear Regression (Baseline)\n",
    "# =====================================\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = lr.predict(X_test)\n",
    "mae, rmse, r2 = eval_metrics(y_test, pred_lr)\n",
    "\n",
    "results[\"Linear Regression\"] = {\n",
    "    \"MAE\": mae,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R2\": r2,\n",
    "    \"pred\": pred_lr,\n",
    "}\n",
    "\n",
    "print(f\"Linear Regression â†’ MAE={mae:.3f} | RMSE={rmse:.3f} | RÂ²={r2:.3f}\")\n",
    "\n",
    "if USE_MLFLOW:\n",
    "    with mlflow.start_run(run_name=\"Linear Regression\"):\n",
    "        mlflow.log_metrics({\n",
    "            \"mae\": mae,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2\": r2\n",
    "        })\n",
    "        mlflow.sklearn.log_model(lr, \"model\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 2ï¸âƒ£ Random Forest Regressor\n",
    "# =====================================\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred_rf = rf.predict(X_test)\n",
    "mae, rmse, r2 = eval_metrics(y_test, pred_rf)\n",
    "\n",
    "results[\"Random Forest\"] = {\n",
    "    \"MAE\": mae,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R2\": r2,\n",
    "    \"pred\": pred_rf,\n",
    "}\n",
    "\n",
    "print(f\"Random Forest â†’ MAE={mae:.3f} | RMSE={rmse:.3f} | RÂ²={r2:.3f}\")\n",
    "\n",
    "if USE_MLFLOW:\n",
    "    with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "        mlflow.log_params({\n",
    "            \"n_estimators\": 200,\n",
    "            \"max_depth\": 15\n",
    "        })\n",
    "        mlflow.log_metrics({\n",
    "            \"mae\": mae,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2\": r2\n",
    "        })\n",
    "        mlflow.sklearn.log_model(rf, \"model\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# Feature Importances (Random Forest)\n",
    "# =====================================\n",
    "\n",
    "fi = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": X_train.columns,\n",
    "        \"importance\": rf.feature_importances_\n",
    "    })\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "display(fi.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a567e20b7adfd0e",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Optional: Prophet (Zeitreihenprognose)\n",
    "\n",
    "Prophet ist ein spezielles Zeitreihenmodell von Facebook, das besonders gut geeignet ist fÃ¼r:\n",
    "\n",
    "- **TÃ¤gliche, wÃ¶chentliche und jÃ¤hrliche SaisonalitÃ¤ten**\n",
    "- **TrendÃ¤nderungen**\n",
    "- **Feiertage und besondere Events**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Vorgehensweise mit Prophet\n",
    "\n",
    "1. **Daten vorbereiten**\n",
    "   - Prophet erwartet zwei Spalten:\n",
    "     - `ds` â†’ Datum/Zeit\n",
    "     - `y` â†’ Zielvariable (Verkehrsaufkommen)\n",
    "\n",
    "2. **Modell definieren**\n",
    "   - SaisonalitÃ¤ten (daily, weekly) automatisch von Prophet erkannt\n",
    "   - Optional: Feiertage als zusÃ¤tzliche Features einbinden\n",
    "\n",
    "3. **Train/Test-Split**\n",
    "   - Chronologisch, wie zuvor, um Data Leakage zu vermeiden\n",
    "\n",
    "4. **Training & Vorhersage**\n",
    "   - Fit auf Trainingsdaten\n",
    "   - Forecast auf Testdaten\n",
    "\n",
    "5. **Evaluation**\n",
    "   - MAE, RMSE, RÂ²\n",
    "   - Vergleich mit Linear Regression und Random Forest\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Ziel\n",
    "\n",
    "- Prophet als **zeitreihenorientierte Alternative** testen\n",
    "- PrÃ¼fen, ob SaisonalitÃ¤ten und Feiertage die Prognose verbessern\n",
    "- Optional: Grundlage fÃ¼r **komplexere Modelle wie LSTM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f903620-64b1-4d3b-b380-dfd9c541227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 6. Optional: Prophet (Zeitreihenprognose)\n",
    "# =====================================\n",
    "\n",
    "if not USE_PROPHET:\n",
    "    print(\"Prophet Ã¼bersprungen.\")\n",
    "else:\n",
    "    # -------------------------------------\n",
    "    # Trainingsdaten fÃ¼r Prophet vorbereiten\n",
    "    # Prophet erwartet nur 'ds' (Datetime) und 'y' (Zielvariable)\n",
    "    # -------------------------------------\n",
    "    prophet_train = train_df[[\"ds\", \"y\"]].copy()\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Prophet Modell definieren\n",
    "    # -------------------------------------\n",
    "    m = Prophet(\n",
    "        yearly_seasonality=False,   # keine jÃ¤hrliche SaisonalitÃ¤t\n",
    "        weekly_seasonality=True,    # wÃ¶chentliche SaisonalitÃ¤t\n",
    "        daily_seasonality=True,     # tÃ¤gliche SaisonalitÃ¤t\n",
    "        interval_width=0.95\n",
    "    )\n",
    "\n",
    "    # Modell trainieren\n",
    "    m.fit(prophet_train)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Vorhersage auf Testdaten\n",
    "    # -------------------------------------\n",
    "    future = m.make_future_dataframe(periods=len(test_df), freq=\"h\")\n",
    "    fc = m.predict(future)\n",
    "\n",
    "    # Prognose fÃ¼r Testzeitraum extrahieren\n",
    "    pred_prophet = fc[\"yhat\"].tail(len(test_df)).to_numpy()\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Evaluation\n",
    "    # -------------------------------------\n",
    "    mae, rmse, r2 = eval_metrics(y_test, pred_prophet)\n",
    "    results[\"Prophet\"] = {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"pred\": pred_prophet\n",
    "    }\n",
    "\n",
    "    print(f\"Prophet â†’ MAE={mae:.3f} | RMSE={rmse:.3f} | RÂ²={r2:.3f}\")\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Optional: MLflow Logging\n",
    "    # -------------------------------------\n",
    "    if USE_MLFLOW:\n",
    "        with mlflow.start_run(run_name=\"Prophet\"):\n",
    "            mlflow.log_metrics({\"mae\": mae, \"rmse\": rmse, \"r2\": r2})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a041571e33006b",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Optional: LSTM (Deep Learning)\n",
    "\n",
    "Long Short-Term Memory (LSTM) ist ein **rekurrentes neuronales Netzwerk**, das speziell fÃ¼r Zeitreihen entwickelt wurde.\n",
    "Es kann **langfristige AbhÃ¤ngigkeiten** und **nichtlineare Muster** erfassen, die klassische Modelle wie Linear Regression oder Random Forest oft nicht erkennen.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Vorgehensweise mit LSTM\n",
    "\n",
    "1. **Daten skalieren**\n",
    "   - LSTM ist empfindlich auf Skalen, daher Normalisierung z.B. mit `MinMaxScaler`.\n",
    "\n",
    "2. **Sequenzielle Features erzeugen**\n",
    "   - Sliding Window Ansatz: fÃ¼r jede Zeitschritt-Vorhersage `y_t`, werden vorherige `n_lags` Werte als Input verwendet.\n",
    "\n",
    "3. **Train/Test Split**\n",
    "   - Wie zuvor, chronologisch, ohne Shuffle.\n",
    "\n",
    "4. **Modellarchitektur**\n",
    "   - LSTM Layer\n",
    "   - Optional Dropout zur Regularisierung\n",
    "   - Dense Output Layer fÃ¼r Regression\n",
    "\n",
    "5. **Training & Vorhersage**\n",
    "   - Loss: Mean Squared Error\n",
    "   - Optimizer: Adam\n",
    "   - Epochs und BatchgrÃ¶ÃŸe definieren\n",
    "\n",
    "6. **Evaluation**\n",
    "   - MAE, RMSE, RÂ²\n",
    "   - Vergleich mit Linear Regression, Random Forest und Prophet\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Ziel\n",
    "\n",
    "- Erfassen komplexer zeitlicher Muster im Verkehr\n",
    "- Vergleich zwischen klassischen Modellen, Prophet und Deep Learning\n",
    "- Optional: Grundlage fÃ¼r weiterfÃ¼hrende Zeitreihenprognosen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b983fea-e364-412a-94be-b748b9e71e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 7. Optional: LSTM (Deep Learning)\n",
    "# =====================================\n",
    "\n",
    "if not USE_TF:\n",
    "    print(\"LSTM Ã¼bersprungen.\")\n",
    "else:\n",
    "    # -------------------------------------\n",
    "    # Helper: Sequenzen erstellen (Sliding Window)\n",
    "    # -------------------------------------\n",
    "    def create_sequences(arr, seq_len=24):\n",
    "        \"\"\"\n",
    "        Erstellt Eingabesequenzen fÃ¼r LSTM.\n",
    "        \"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(len(arr) - seq_len):\n",
    "            X.append(arr[i:i + seq_len])\n",
    "            y.append(arr[i + seq_len])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Zielvariable skalieren\n",
    "    # -------------------------------------\n",
    "    scaler = MinMaxScaler()\n",
    "    y_scaled = scaler.fit_transform(df[\"y\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "    # Sequenzen erstellen\n",
    "    X_seq, y_seq = create_sequences(y_scaled, seq_len=24)\n",
    "\n",
    "    # Chronologischer Train/Test-Split\n",
    "    split = int(len(X_seq) * 0.8)\n",
    "    X_tr, y_tr = X_seq[:split], y_seq[:split]\n",
    "    X_te, y_te = X_seq[split:], y_seq[split:]\n",
    "\n",
    "    # Input fÃ¼r LSTM: (samples, timesteps, features)\n",
    "    X_tr = X_tr.reshape((X_tr.shape[0], X_tr.shape[1], 1))\n",
    "    X_te = X_te.reshape((X_te.shape[0], X_te.shape[1], 1))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # LSTM Modell definieren\n",
    "    # -------------------------------------\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation=\"relu\", input_shape=(24, 1), return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Training\n",
    "    # -------------------------------------\n",
    "    history = model.fit(\n",
    "        X_tr, y_tr,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Vorhersage & Inverse Scaling\n",
    "    # -------------------------------------\n",
    "    pred_scaled = model.predict(X_te, verbose=0)\n",
    "    pred = scaler.inverse_transform(pred_scaled).ravel()\n",
    "    y_true = scaler.inverse_transform(y_te.reshape(-1, 1)).ravel()\n",
    "\n",
    "    # Metriken berechnen\n",
    "    mae, rmse, r2 = eval_metrics(y_true, pred)\n",
    "    pred_aligned = pred[:len(y_test)]  # optional an TestdatenlÃ¤nge anpassen\n",
    "    results[\"LSTM\"] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"pred\": pred_aligned}\n",
    "\n",
    "    print(f\"LSTM â†’ MAE={mae:.3f} | RMSE={rmse:.3f} | RÂ²={r2:.3f}\")\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Optional: MLflow Logging\n",
    "    # -------------------------------------\n",
    "    if USE_MLFLOW:\n",
    "        with mlflow.start_run(run_name=\"LSTM\"):\n",
    "            mlflow.log_params({\"epochs\": 30, \"batch_size\": 32})\n",
    "            mlflow.log_metrics({\"mae\": mae, \"rmse\": rmse, \"r2\": r2})\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Trainingsverlauf plotten\n",
    "    # -------------------------------------\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val loss\")\n",
    "    plt.title(\"LSTM Training History\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8faf3ce400da924",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Modellvergleich\n",
    "\n",
    "In diesem Abschnitt werden die bisherigen Modelle **Linear Regression, Random Forest, Prophet**\n",
    "und optional **LSTM** miteinander verglichen, um die PrognosequalitÃ¤t zu bewerten.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Vergleichskriterien\n",
    "\n",
    "- **MAE** â†’ Mittlerer absoluter Fehler\n",
    "- **RMSE** â†’ Wurzel des mittleren quadratischen Fehlers\n",
    "- **RÂ²** â†’ GÃ¼temaÃŸ fÃ¼r die erklÃ¤rte Varianz\n",
    "- Visuelle GegenÃ¼berstellung: **Ist vs. Vorhersage**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š Vorgehensweise\n",
    "\n",
    "1. Ergebnisse aus allen Modellen in einer **Tabelle zusammenfassen**\n",
    "2. **Balkendiagramme** fÃ¼r MAE, RMSE, RÂ² erstellen\n",
    "3. Zeitreihenplot: **Ist vs. Prognose** fÃ¼r alle Modelle\n",
    "4. Optional: **Feature Importances** fÃ¼r Random Forest darstellen\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Ziel\n",
    "\n",
    "- Schneller Ãœberblick, welches Modell die beste Prognose liefert\n",
    "- Identifikation von StÃ¤rken / SchwÃ¤chen klassischer vs. zeitreihen- bzw. Deep Learning-Modelle\n",
    "- Grundlage fÃ¼r weitere Optimierungen oder produktive Nutzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b3a43-3393-4f61-a105-c049730cbc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 8. Modellvergleich\n",
    "# =====================================\n",
    "\n",
    "# -------------------------------------\n",
    "# Ergebnisse aller Modelle in DataFrame zusammenfassen\n",
    "# -------------------------------------\n",
    "rows = [\n",
    "    {\"model\": name, \"MAE\": d[\"MAE\"], \"RMSE\": d[\"RMSE\"], \"R2\": d[\"R2\"]}\n",
    "    for name, d in results.items()\n",
    "]\n",
    "\n",
    "results_df = (\n",
    "    pd.DataFrame(rows)\n",
    "    .set_index(\"model\")\n",
    "    .sort_values(\"MAE\")  # nach MAE aufsteigend sortieren\n",
    ")\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "# -------------------------------------\n",
    "# Balkendiagramme fÃ¼r MAE, RMSE, RÂ²\n",
    "# -------------------------------------\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# MAE\n",
    "axes[0].bar(results_df.index, results_df[\"MAE\"])\n",
    "axes[0].set_title(\"MAE\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# RMSE\n",
    "axes[1].bar(results_df.index, results_df[\"RMSE\"])\n",
    "axes[1].set_title(\"RMSE\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# RÂ²\n",
    "axes[2].bar(results_df.index, results_df[\"R2\"])\n",
    "axes[2].set_title(\"RÂ²\")\n",
    "axes[2].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------\n",
    "# Bestes Modell identifizieren\n",
    "# -------------------------------------\n",
    "best = results_df.index[0]\n",
    "print(f\"Bestes Modell: {best} (MAE={results_df.loc[best, 'MAE']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726aedaa89feee6",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Vorhersagen visualisieren\n",
    "\n",
    "In diesem Abschnitt werden die Vorhersagen der Modelle **gegenÃ¼ber den echten Verkehrsdaten** dargestellt.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Ziele der Visualisierung\n",
    "\n",
    "1. **Vergleich von Ist vs. Prognose**\n",
    "   - Erkennen von Mustern, z.â€¯B. Rush-Hour, Wochenend-Effekte\n",
    "2. **Modellvergleich auf Zeitachse**\n",
    "   - Welches Modell folgt dem realen Verlauf am besten?\n",
    "3. **EinschÃ¤tzung der VorhersagequalitÃ¤t**\n",
    "   - ErgÃ¤nzt die Metriken (MAE, RMSE, RÂ²) durch visuelle Analyse\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š Vorgehensweise\n",
    "\n",
    "- Linienplot Ã¼ber den Testzeitraum\n",
    "- Jede Modellvorhersage als eigene Linie\n",
    "- Originalwerte (`y_test`) als Referenz\n",
    "- Optional: farbliche Hervorhebung des besten Modells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac2e0c7-1a22-4cda-9482-456d06f00cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 9. Vorhersagen visualisieren\n",
    "# =====================================\n",
    "\n",
    "# FenstergrÃ¶ÃŸe fÃ¼r Plot (max. 1 Woche)\n",
    "test_window = min(len(y_test), 7 * 24)\n",
    "\n",
    "# Anzahl Modelle und Subplot-Layout\n",
    "n_models = len(results)\n",
    "ncols = 2\n",
    "nrows = int(np.ceil(n_models / ncols))\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(16, 4 * nrows), squeeze=False)\n",
    "\n",
    "# -------------------------------------\n",
    "# Plot Ist vs. Prognose fÃ¼r jedes Modell\n",
    "# -------------------------------------\n",
    "for (name, d), ax in zip(results.items(), axes.ravel()):\n",
    "    # Echte Werte\n",
    "    ax.plot(range(test_window), y_test[:test_window], label=\"Ist\", linewidth=2)\n",
    "    # Modellvorhersage\n",
    "    ax.plot(range(test_window), d[\"pred\"][:test_window], label=\"Prognose\",\n",
    "            linewidth=2, linestyle=\"--\")\n",
    "\n",
    "    ax.set_title(f\"{name} (MAE={d['MAE']:.2f})\")\n",
    "    ax.set_xlabel(\"Stunde im Test\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Leere Subplots ausblenden\n",
    "for ax in axes.ravel()[n_models:]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4188fa97c3d5995",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Optional: Random Forest Tuning\n",
    "\n",
    "In diesem Abschnitt wird der **Random Forest Regressor** optimiert, um die PrognosequalitÃ¤t zu verbessern.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Ziele des Tunings\n",
    "\n",
    "1. **Hyperparameter-Optimierung**:\n",
    "   - Anzahl der BÃ¤ume (`n_estimators`)\n",
    "   - Maximale Baumtiefe (`max_depth`)\n",
    "   - Minimale Samples pro Blatt (`min_samples_leaf`)\n",
    "2. **Leistungssteigerung**:\n",
    "   - Bessere Modellanpassung ohne Overfitting\n",
    "3. **Evaluation mit TimeSeriesSplit**:\n",
    "   - Zeitreihen-konformer Cross-Validation\n",
    "   - Vermeidung von Data Leakage\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š Vorgehensweise\n",
    "\n",
    "1. **Parameter-Raster definieren** fÃ¼r GridSearchCV\n",
    "2. **TimeSeriesSplit** fÃ¼r trainierende Teilmengen\n",
    "3. **GridSearchCV** zur Auswahl der besten Parameter\n",
    "4. **Bestes Modell trainieren** und auf Testdaten evaluieren\n",
    "5. Optional: **MLflow Logging** der Hyperparameter und Metriken\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Ziel\n",
    "\n",
    "- Den Random Forest optimal an die Verkehrszeitreihe anpassen\n",
    "- Vergleich mit vorherigen Standardmodellen (Linear Regression, RF baseline, Prophet, LSTM)\n",
    "- Grundlage fÃ¼r produktive Vorhersagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dde2be-91c2-426a-893c-c9ae58743ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# 10. Optional: Random Forest Tuning\n",
    "# =====================================\n",
    "\n",
    "DO_TUNING = True\n",
    "\n",
    "if DO_TUNING:\n",
    "    # -------------------------------------\n",
    "    # TimeSeriesSplit fÃ¼r Cross-Validation\n",
    "    # -------------------------------------\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Parameter-Raster fÃ¼r GridSearchCV\n",
    "    # -------------------------------------\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [10, 15, 20],\n",
    "        \"min_samples_split\": [2, 10]\n",
    "    }\n",
    "\n",
    "    # Basis-Modell\n",
    "    base = RandomForestRegressor(random_state=RANDOM_SEED, n_jobs=-1)\n",
    "\n",
    "    # GridSearchCV mit Zeitreihen-CV\n",
    "    gs = GridSearchCV(\n",
    "        base,\n",
    "        param_grid=param_grid,\n",
    "        cv=tscv,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Training / Hyperparameter-Suche\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Beste Parameter\n",
    "    print(f\"Beste Parameter: {gs.best_params_}\")\n",
    "\n",
    "    # Vorhersage auf Testdaten\n",
    "    pred = gs.predict(X_test)\n",
    "    mae, rmse, r2 = eval_metrics(y_test, pred)\n",
    "    print(f\"Tuned RF â†’ MAE={mae:.3f} | RMSE={rmse:.3f} | RÂ²={r2:.3f}\")\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Optional: MLflow Logging\n",
    "    # -------------------------------------\n",
    "    if USE_MLFLOW:\n",
    "        with mlflow.start_run(run_name=\"RF GridSearch\"):\n",
    "            mlflow.log_params(gs.best_params_)\n",
    "            mlflow.log_metrics({\"mae\": mae, \"rmse\": rmse, \"r2\": r2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464e5c2337ed4b7",
   "metadata": {},
   "source": [
    "## ğŸ“ Zusammenfassung\n",
    "\n",
    "Dieses Notebook zeigt eine **komplette Pipeline fÃ¼r Verkehrsprognosen**:\n",
    "\n",
    "- Daten synthetisch generieren oder CSV laden\n",
    "- Explorative Datenanalyse (EDA)\n",
    "- Feature Engineering (Lag, Rolling, Kalender, Wetter)\n",
    "- Modelle: Linear Regression, Random Forest, Prophet, optional LSTM\n",
    "- Modellvergleich & Visualisierung\n",
    "- Optional: Random Forest Hyperparameter-Tuning\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ NÃ¤chste Schritte / Empfehlungen\n",
    "\n",
    "- **Echte Verkehrsdaten anbinden** (CSV, API oder Datenbank)\n",
    "- **Externe Features erweitern** (Wetter, Events, Ferienkalender)\n",
    "- **Robustes Backtesting** mit Rolling Origin Cross-Validation\n",
    "- **Deployment**: z.â€¯B. Streamlit-App oder REST-Service mit gespeicherten Modellartefakten\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
