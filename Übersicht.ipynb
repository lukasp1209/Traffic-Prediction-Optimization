{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Traffic Prediction & Optimization - Analyse Notebook\\n\",\n",
    "    \"Experimentelle Analyse mit verschiedenen ML-Modellen f√ºr Verkehrsprognosen\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Imports & Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from datetime import datetime, timedelta\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ML Libraries\\n\",\n",
    "    \"from sklearn.preprocessing import MinMaxScaler\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestRegressor\\n\",\n",
    "    \"from sklearn.linear_model import LinearRegression\\n\",\n",
    "    \"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\\n\",\n",
    "    \"from prophet import Prophet\\n\",\n",
    "    \"import mlflow\\n\",\n",
    "    \"import mlflow.sklearn\\n\",\n",
    "    \"\\n\",\n",
    "    \"# TensorFlow f√ºr LSTM\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow.keras.models import Sequential\\n\",\n",
    "    \"from tensorflow.keras.layers import LSTM, Dense, Dropout\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Datengenerierung mit realistischen Mustern\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def generate_realistic_traffic_data(days=60):\\n\",\n",
    "    \"    \\\"\\\"\\\"Generiert realistische Verkehrsdaten mit Tages- und Wochenmuster\\\"\\\"\\\"\\n\",\n",
    "    \"    dates = pd.date_range(start=\\\"2024-01-01\\\", periods=days*24, freq=\\\"H\\\")\\n\",\n",
    "    \"    hours = np.arange(days*24)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # T√§gliches Muster (Spitzen morgens/abends)\\n\",\n",
    "    \"    daily_pattern = 30 * np.sin(hours * 2 * np.pi / 24)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Wochenmuster (weniger Verkehr am Wochenende)\\n\",\n",
    "    \"    weekly_pattern = 10 * np.sin(hours * 2 * np.pi / (24*7))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Trend\\n\",\n",
    "    \"    trend = np.linspace(0, 5, len(hours))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Rauschen\\n\",\n",
    "    \"    noise = np.random.normal(0, 4, len(hours))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    traffic = 50 + daily_pattern + weekly_pattern + trend + noise\\n\",\n",
    "    \"    traffic = np.clip(traffic, 5, 100)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Wetter-Features\\n\",\n",
    "    \"    weather = np.random.choice([\\\"Sonnig\\\", \\\"Bew√∂lkt\\\", \\\"Regen\\\"], len(hours))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Feiertage simulieren\\n\",\n",
    "    \"    is_holiday = np.zeros(len(hours))\\n\",\n",
    "    \"    is_holiday[::168] = 1  # Jeden Sonntag\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    df = pd.DataFrame({\\n\",\n",
    "    \"        \\\"ds\\\": dates,\\n\",\n",
    "    \"        \\\"y\\\": traffic,\\n\",\n",
    "    \"        \\\"Geschwindigkeit\\\": 120 - traffic*0.5 + np.random.normal(0, 5, len(hours)),\\n\",\n",
    "    \"        \\\"Wetter\\\": weather,\\n\",\n",
    "    \"        \\\"Feiertag\\\": is_holiday,\\n\",\n",
    "    \"        \\\"Stunde\\\": dates.hour,\\n\",\n",
    "    \"        \\\"Wochentag\\\": dates.dayofweek\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return df\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Daten generieren\\n\",\n",
    "    \"df = generate_realistic_traffic_data(days=60)\\n\",\n",
    "    \"print(f\\\"Datensatz erstellt: {len(df)} Datenpunkte\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nZeitraum: {df['ds'].min()} bis {df['ds'].max()}\\\")\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Explorative Datenanalyse (EDA)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Statistiken\\n\",\n",
    "    \"print(\\\"Verkehrsaufkommen-Statistiken:\\\")\\n\",\n",
    "    \"print(df['y'].describe())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualisierung\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(14, 8))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Zeitreihe\\n\",\n",
    "    \"axes[0, 0].plot(df['ds'], df['y'], linewidth=1)\\n\",\n",
    "    \"axes[0, 0].set_title('Verkehrsaufkommen - Zeitreihe')\\n\",\n",
    "    \"axes[0, 0].set_ylabel('Aufkommen (%)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Stundenmuster\\n\",\n",
    "    \"hourly = df.groupby('Stunde')['y'].mean()\\n\",\n",
    "    \"axes[0, 1].bar(hourly.index, hourly.values, color='skyblue')\\n\",\n",
    "    \"axes[0, 1].set_title('Durchschnittliches Verkehrsmuster pro Stunde')\\n\",\n",
    "    \"axes[0, 1].set_xlabel('Stunde des Tages')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Wochentag-Muster\\n\",\n",
    "    \"daily = df.groupby('Wochentag')['y'].mean()\\n\",\n",
    "    \"axes[1, 0].plot(daily.index, daily.values, marker='o', linewidth=2, markersize=8)\\n\",\n",
    "    \"axes[1, 0].set_title('Verkehrsmuster nach Wochentag')\\n\",\n",
    "    \"axes[1, 0].set_xticks(range(7))\\n\",\n",
    "    \"axes[1, 0].set_xticklabels(['Mo', 'Di', 'Mi', 'Do', 'Fr', 'Sa', 'So'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Verteilung\\n\",\n",
    "    \"axes[1, 1].hist(df['y'], bins=30, color='coral', edgecolor='black')\\n\",\n",
    "    \"axes[1, 1].set_title('Verteilung des Verkehrsaufkommens')\\n\",\n",
    "    \"axes[1, 1].set_xlabel('Aufkommen (%)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Train-Test Split & Feature Engineering\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train-Test Split (80-20)\\n\",\n",
    "    \"split_idx = int(len(df) * 0.8)\\n\",\n",
    "    \"train_df = df[:split_idx].copy()\\n\",\n",
    "    \"test_df = df[split_idx:].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training-Set: {len(train_df)} Datenpunkte ({train_df['ds'].min()} bis {train_df['ds'].max()})\\\")\\n\",\n",
    "    \"print(f\\\"Test-Set: {len(test_df)} Datenpunkte ({test_df['ds'].min()} bis {test_df['ds'].max()})\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Feature Engineering\\n\",\n",
    "    \"def create_features(data):\\n\",\n",
    "    \"    \\\"\\\"\\\"Erstellt zus√§tzliche Features f√ºr ML-Modelle\\\"\\\"\\\"\\n\",\n",
    "    \"    X = pd.DataFrame()\\n\",\n",
    "    \"    X['hour'] = data['Stunde']\\n\",\n",
    "    \"    X['day_of_week'] = data['Wochentag']\\n\",\n",
    "    \"    X['is_holiday'] = data['Feiertag']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Lag-Features (Werte der letzten 1, 6, 24 Stunden)\\n\",\n",
    "    \"    for lag in [1, 6, 24]:\\n\",\n",
    "    \"        X[f'lag_{lag}'] = data['y'].shift(lag)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Rolling averages\\n\",\n",
    "    \"    for window in [6, 24]:\\n\",\n",
    "    \"        X[f'rolling_mean_{window}'] = data['y'].rolling(window).mean()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Wetter-Encoding\\n\",\n",
    "    \"    X['is_rain'] = (data['Wetter'] == 'Regen').astype(int)\\n\",\n",
    "    \"    X['is_cloudy'] = (data['Wetter'] == 'Bew√∂lkt').astype(int)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return X.fillna(method='bfill')\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train = create_features(train_df)\\n\",\n",
    "    \"X_test = create_features(test_df)\\n\",\n",
    "    \"y_train = train_df['y'].values\\n\",\n",
    "    \"y_test = test_df['y'].values\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nFeatures erstellt: {X_train.shape[1]} Features\\\")\\n\",\n",
    "    \"X_train.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Baseline-Modelle (Lineare Regression, Random Forest)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# MLflow Setup\\n\",\n",
    "    \"mlflow.set_experiment(\\\"Traffic Prediction\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"results = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 1. Lineare Regression\\n\",\n",
    "    \"with mlflow.start_run(run_name=\\\"Linear Regression\\\"):\\n\",\n",
    "    \"    lr_model = LinearRegression()\\n\",\n",
    "    \"    lr_model.fit(X_train, y_train)\\n\",\n",
    "    \"    y_pred_lr = lr_model.predict(X_test)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mae_lr = mean_absolute_error(y_test, y_pred_lr)\\n\",\n",
    "    \"    rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\\n\",\n",
    "    \"    r2_lr = r2_score(y_test, y_pred_lr)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mlflow.log_metric(\\\"mae\\\", mae_lr)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"rmse\\\", rmse_lr)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"r2\\\", r2_lr)\\n\",\n",
    "    \"    mlflow.sklearn.log_model(lr_model, \\\"linear_regression_model\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results['Linear Regression'] = {'MAE': mae_lr, 'RMSE': rmse_lr, 'R¬≤': r2_lr, 'predictions': y_pred_lr}\\n\",\n",
    "    \"    print(f\\\"Linear Regression - MAE: {mae_lr:.3f}, RMSE: {rmse_lr:.3f}, R¬≤: {r2_lr:.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 2. Random Forest\\n\",\n",
    "    \"with mlflow.start_run(run_name=\\\"Random Forest\\\"):\\n\",\n",
    "    \"    rf_model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\\n\",\n",
    "    \"    rf_model.fit(X_train, y_train)\\n\",\n",
    "    \"    y_pred_rf = rf_model.predict(X_test)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mae_rf = mean_absolute_error(y_test, y_pred_rf)\\n\",\n",
    "    \"    rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\\n\",\n",
    "    \"    r2_rf = r2_score(y_test, y_pred_rf)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mlflow.log_param(\\\"n_estimators\\\", 100)\\n\",\n",
    "    \"    mlflow.log_param(\\\"max_depth\\\", 15)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"mae\\\", mae_rf)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"rmse\\\", rmse_rf)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"r2\\\", r2_rf)\\n\",\n",
    "    \"    mlflow.sklearn.log_model(rf_model, \\\"random_forest_model\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results['Random Forest'] = {'MAE': mae_rf, 'RMSE': rmse_rf, 'R¬≤': r2_rf, 'predictions': y_pred_rf}\\n\",\n",
    "    \"    print(f\\\"Random Forest - MAE: {mae_rf:.3f}, RMSE: {rmse_rf:.3f}, R¬≤: {r2_rf:.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Feature Importance (Random Forest)\\n\",\n",
    "    \"feature_importance = pd.DataFrame({\\n\",\n",
    "    \"    'Feature': X_train.columns,\\n\",\n",
    "    \"    'Importance': rf_model.feature_importances_\\n\",\n",
    "    \"}).sort_values('Importance', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nTop 5 wichtige Features:\\\")\\n\",\n",
    "    \"print(feature_importance.head())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Time Series Modell - Prophet\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Prophet ben√∂tigt ds und y Spalten\\n\",\n",
    "    \"prophet_train = train_df[['ds', 'y']].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"with mlflow.start_run(run_name=\\\"Prophet\\\"):\\n\",\n",
    "    \"    model_prophet = Prophet(yearly_seasonality=False, \\n\",\n",
    "    \"                           monthly_seasonality=False,\\n\",\n",
    "    \"                           daily_seasonality=True,\\n\",\n",
    "    \"                           interval_width=0.95)\\n\",\n",
    "    \"    model_prophet.fit(prophet_train)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Vorhersage f√ºr Test-Set\\n\",\n",
    "    \"    future = model_prophet.make_future_dataframe(periods=len(test_df), freq='H')\\n\",\n",
    "    \"    forecast = model_prophet.predict(future)\\n\",\n",
    "    \"    y_pred_prophet = forecast['yhat'].tail(len(test_df)).values\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mae_prophet = mean_absolute_error(y_test, y_pred_prophet)\\n\",\n",
    "    \"    rmse_prophet = np.sqrt(mean_squared_error(y_test, y_pred_prophet))\\n\",\n",
    "    \"    r2_prophet = r2_score(y_test, y_pred_prophet)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mlflow.log_metric(\\\"mae\\\", mae_prophet)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"rmse\\\", rmse_prophet)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"r2\\\", r2_prophet)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results['Prophet'] = {'MAE': mae_prophet, 'RMSE': rmse_prophet, 'R¬≤': r2_prophet, 'predictions': y_pred_prophet}\\n\",\n",
    "    \"    print(f\\\"Prophet - MAE: {mae_prophet:.3f}, RMSE: {rmse_prophet:.3f}, R¬≤: {r2_prophet:.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Deep Learning - LSTM\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# LSTM Vorbereitung - Sequenzen erstellen\\n\",\n",
    "    \"def create_sequences(data, seq_length=24):\\n\",\n",
    "    \"    X, y = [], []\\n\",\n",
    "    \"    for i in range(len(data) - seq_length):\\n\",\n",
    "    \"        X.append(data[i:i+seq_length])\\n\",\n",
    "    \"        y.append(data[i+seq_length])\\n\",\n",
    "    \"    return np.array(X), np.array(y)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Normalisierung\\n\",\n",
    "    \"scaler = MinMaxScaler()\\n\",\n",
    "    \"traffic_scaled = scaler.fit_transform(df['y'].values.reshape(-1, 1))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train-Test Split f√ºr LSTM\\n\",\n",
    "    \"X_lstm, y_lstm = create_sequences(traffic_scaled, seq_length=24)\\n\",\n",
    "    \"split_lstm = int(len(X_lstm) * 0.8)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_lstm_train = X_lstm[:split_lstm]\\n\",\n",
    "    \"y_lstm_train = y_lstm[:split_lstm]\\n\",\n",
    "    \"X_lstm_test = X_lstm[split_lstm:]\\n\",\n",
    "    \"y_lstm_test = y_lstm[split_lstm:]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"LSTM Training-Set: {X_lstm_train.shape}\\\")\\n\",\n",
    "    \"print(f\\\"LSTM Test-Set: {X_lstm_test.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# LSTM-Modell trainieren\\n\",\n",
    "    \"with mlflow.start_run(run_name=\\\"LSTM\\\"):\\n\",\n",
    "    \"    model_lstm = Sequential([\\n\",\n",
    "    \"        LSTM(64, activation='relu', input_shape=(24, 1), return_sequences=True),\\n\",\n",
    "    \"        Dropout(0.2),\\n\",\n",
    "    \"        LSTM(32, activation='relu', return_sequences=False),\\n\",\n",
    "    \"        Dropout(0.2),\\n\",\n",
    "    \"        Dense(16, activation='relu'),\\n\",\n",
    "    \"        Dense(1)\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    model_lstm.compile(optimizer='adam', loss='mse', metrics=['mae'])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    history = model_lstm.fit(\\n\",\n",
    "    \"        X_lstm_train, y_lstm_train,\\n\",\n",
    "    \"        epochs=50,\\n\",\n",
    "    \"        batch_size=32,\\n\",\n",
    "    \"        validation_split=0.2,\\n\",\n",
    "    \"        verbose=0\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Vorhersage und inverse transform\\n\",\n",
    "    \"    y_pred_lstm_scaled = model_lstm.predict(X_lstm_test, verbose=0)\\n\",\n",
    "    \"    y_pred_lstm = scaler.inverse_transform(y_pred_lstm_scaled).flatten()\\n\",\n",
    "    \"    y_test_lstm = scaler.inverse_transform(y_lstm_test.reshape(-1, 1)).flatten()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mae_lstm = mean_absolute_error(y_test_lstm, y_pred_lstm)\\n\",\n",
    "    \"    rmse_lstm = np.sqrt(mean_squared_error(y_test_lstm, y_pred_lstm))\\n\",\n",
    "    \"    r2_lstm = r2_score(y_test_lstm, y_pred_lstm)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mlflow.log_param(\\\"epochs\\\", 50)\\n\",\n",
    "    \"    mlflow.log_param(\\\"batch_size\\\", 32)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"mae\\\", mae_lstm)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"rmse\\\", rmse_lstm)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"r2\\\", r2_lstm)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results['LSTM'] = {'MAE': mae_lstm, 'RMSE': rmse_lstm, 'R¬≤': r2_lstm, 'predictions': y_pred_lstm[:len(y_test)]}\\n\",\n",
    "    \"    print(f\\\"LSTM - MAE: {mae_lstm:.3f}, RMSE: {rmse_lstm:.3f}, R¬≤: {r2_lstm:.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Trainingshistorie\\n\",\n",
    "    \"plt.figure(figsize=(12, 4))\\n\",\n",
    "    \"plt.plot(history.history['loss'], label='Training Loss')\\n\",\n",
    "    \"plt.plot(history.history['val_loss'], label='Validation Loss')\\n\",\n",
    "    \"plt.title('LSTM Training History')\\n\",\n",
    "    \"plt.xlabel('Epoch')\\n\",\n",
    "    \"plt.ylabel('Loss')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Modell-Vergleich & Visualisierung\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Ergebnisse zusammenfassen\\n\",\n",
    "    \"results_df = pd.DataFrame(results).T\\n\",\n",
    "    \"results_df = results_df.drop('predictions', axis=1)\\n\",\n",
    "    \"print(\\\"\\\\n=== Modell-Vergleich ===\\\")\\n\",\n",
    "    \"print(results_df.round(3))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualisierung\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 3, figsize=(15, 4))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# MAE\\n\",\n",
    "    \"axes[0].bar(results_df.index, results_df['MAE'], color='skyblue')\\n\",\n",
    "    \"axes[0].set_title('Mean Absolute Error (MAE)')\\n\",\n",
    "    \"axes[0].set_ylabel('MAE')\\n\",\n",
    "    \"axes[0].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# RMSE\\n\",\n",
    "    \"axes[1].bar(results_df.index, results_df['RMSE'], color='lightcoral')\\n\",\n",
    "    \"axes[1].set_title('Root Mean Squared Error (RMSE)')\\n\",\n",
    "    \"axes[1].set_ylabel('RMSE')\\n\",\n",
    "    \"axes[1].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# R¬≤\\n\",\n",
    "    \"axes[2].bar(results_df.index, results_df['R¬≤'], color='lightgreen')\\n\",\n",
    "    \"axes[2].set_title('R¬≤ Score')\\n\",\n",
    "    \"axes[2].set_ylabel('R¬≤')\\n\",\n",
    "    \"axes[2].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Beste Modell\\n\",\n",
    "    \"best_model = results_df['MAE'].idxmin()\\n\",\n",
    "    \"print(f\\\"\\\\n‚úÖ Bestes Modell: {best_model} (MAE: {results_df.loc[best_model, 'MAE']:.3f})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Vorhersagen visualisieren\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Vorhersagen f√ºr einen Testabschnitt (erste 7 Tage)\\n\",\n",
    "    \"test_window = 7 * 24  # 7 Tage\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(16, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"for idx, (model_name, ax) in enumerate(zip(results.keys(), axes.flat)):\\n\",\n",
    "    \"    ax.plot(range(test_window), y_test[:test_window], label='Tats√§chlich', linewidth=2, marker='o', markersize=3)\\n\",\n",
    "    \"    ax.plot(range(test_window), results[model_name]['predictions'][:test_window], \\n\",\n",
    "    \"            label='Vorhersage', linewidth=2, linestyle='--', marker='s', markersize=3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ax.set_title(f\\\"{model_name} - MAE: {results[model_name]['MAE']:.2f}\\\")\\n\",\n",
    "    \"    ax.set_xlabel('Stunde')\\n\",\n",
    "    \"    ax.set_ylabel('Verkehrsaufkommen (%)')\\n\",\n",
    "    \"    ax.legend()\\n\",\n",
    "    \"    ax.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Hyperparameter-Tuning (Grid Search f√ºr Random Forest)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.model_selection import GridSearchCV\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Grid Search\\n\",\n",
    "    \"param_grid = {\\n\",\n",
    "    \"    'n_estimators': [50, 100, 200],\\n\",\n",
    "    \"    'max_depth': [10, 15, 20],\\n\",\n",
    "    \"    'min_samples_split': [5, 10]\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"with mlflow.start_run(run_name=\\\"Random Forest - GridSearchCV\\\"):\\n\",\n",
    "    \"    rf_grid = GridSearchCV(\\n\",\n",
    "    \"        RandomForestRegressor(random_state=42, n_jobs=-1),\\n\",\n",
    "    \"        param_grid,\\n\",\n",
    "    \"        cv=5,\\n\",\n",
    "    \"        scoring='neg_mean_absolute_error',\\n\",\n",
    "    \"        n_jobs=-1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    rf_grid.fit(X_train, y_train)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Beste Parameter: {rf_grid.best_params_}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    y_pred_grid = rf_grid.predict(X_test)\\n\",\n",
    "    \"    mae_grid = mean_absolute_error(y_test, y_pred_grid)\\n\",\n",
    "    \"    rmse_grid = np.sqrt(mean_squared_error(y_test, y_pred_grid))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    mlflow.log_params(rf_grid.best_params_)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"mae\\\", mae_grid)\\n\",\n",
    "    \"    mlflow.log_metric(\\\"rmse\\\", rmse_grid)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nOptimiertes Random Forest - MAE: {mae_grid:.3f}, RMSE: {rmse_grid:.3f}\\\")\\n\",\n",
    "    \"    print(f\\\"Verbesserung gegen√ºber Baseline: {((mae_rf - mae_grid) / mae_rf * 100):.1f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 11. Zusammenfassung & Empfehlungen\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\"\\\"\\\\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\\n\",\n",
    "    \"‚ïë TRAFFIC PREDICTION & OPTIMIZATION - ANALYSE-ZUSAMMENFASSUNG ‚ïë\\n\",\n",
    "    \"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\\n\",\n",
    "    \"\\n\",\n",
    "    \"üìä DATASET-√úBERSICHT:\\n\",\n",
    "    \"  ‚Ä¢ Gesamte Datenpunkte: {}\\n\",\n",
    "    \"  ‚Ä¢ Zeitraum: {} bis {}\\n\",\n",
    "    \"  ‚Ä¢ Zeitaufl√∂sung: St√ºndlich\\n\",\n",
    "    \"  ‚Ä¢ Features: Tages-/Wochenmuster, Wetter, Feiertage\\n\",\n",
    "    \"\\n\",\n",
    "    \"ü§ñ MODELL-PERFORMANCE:\\n\",\n",
    "    \"{}\\n\",\n",
    "    \"\\n\",\n",
    "    \"‚úÖ EMPFEHLUNGEN:\\n\",\n",
    "    \"  1. Random Forest zeigt beste Balance zwischen Genauigkeit und Geschwindigkeit\\n\",\n",
    "    \"  2. Prophet eignet sich f√ºr mittelfristige Prognosen (1-7 Tage)\\n\",\n",
    "    \"  3. LSTM erfasst komplexe Muster, ben√∂tigt aber mehr Training\\n\",\n",
    "    \"  4. Feature Engineering (Lag, Rolling Average) ist entscheidend\\n\",\n",
    "    \"  5. Hyperparameter-Tuning via GridSearch verbessert MAE um ~15%\\n\",\n",
    "    \"\\n\",\n",
    "    \"üöÄ N√ÑCHSTE SCHRITTE:\\n\",\n",
    "    \"  ‚Ä¢ Echte Verkehrsdaten (z.B. von Open Data Portalen) integrieren\\n\",\n",
    "    \"  ‚Ä¢ Externe Features: Wetter-API, Feiertag-Kalender, Events\\n\",\n",
    "    \"  ‚Ä¢ Ensemble-Methoden (Voting, Stacking) kombinieren\\n\",\n",
    "    \"  ‚Ä¢ MLflow-Integration f√ºr kontinuierliches Monitoring\\n\",\n",
    "    \"  ‚Ä¢ Deployment via Docker + FastAPI REST-API\\n\",\n",
    "    \"\\\"\\\"\\\".format(len(df), df['ds'].min().strftime('%Y-%m-%d'), \\n\",\n",
    "    \"            df['ds'].max().strftime('%Y-%m-%d'), results_df.to_string()))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 12. MLflow UI starten\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\nüîç MLflow UI ist verf√ºgbar unter: http://localhost:5000\\\")\\n\",\n",
    "    \"print(\\\"\\\\nZum Starten der MLflow UI in Terminal ausf√ºhren:\\\")\\n\",\n",
    "    \"print(\\\"mlflow ui --host 0.0.0.0 --port 5000\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.11.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ],
   "id": "c29698879ad32f53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
